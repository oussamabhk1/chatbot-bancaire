# -*- coding: utf-8 -*-
"""working_llama_textuel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Av8mYkJJtH41YE7is7w5Zx7svQq_OxTN
"""

from groq import Groq
import os

# Set API key directly
os.environ["GROQ_API_KEY"] = "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"

# Language detection (basic)
def detect_language(text):
    if any('\u0600' <= c <= '\u06FF' for c in text):  # Arabic script
        return 'ar'
    elif re.search(r'[àâçéèêëîïôûùüÿñæœ]', text.lower()):  # French special chars
        return 'fr'
    else:
        return 'en'

# Load the CSV into a DataFrame
def load_faq_data(file_path):
    df = pd.read_csv(file_path)
    return df.to_dict(orient='records')

# Get response based on exact match
def get_answer_from_question(question, faq_data):
    lang = detect_language(question.strip().lower())

    for entry in faq_data:
        if lang == 'en' and entry['Question'].strip().lower() == question.strip().lower():
            return entry['Answer']
        elif lang == 'fr' and entry['Question_fr'].strip().lower() == question.strip().lower():
            return entry['Answer_fr']
        elif lang == 'ar' and entry['Question_ar'].strip() == question.strip():
            return entry['Answer_ar']

    # If no exact match, use Groq model for fuzzy match
    return fallback_to_groq(question, lang, faq_data)

# Fallback to Groq model for fuzzy matching
def fallback_to_groq(question, lang, faq_data):
    system_prompt = f"""
    You are a multilingual assistant trained to answer banking-related questions.

    Instructions:
    - Match the user's question to the most relevant row in the provided JSON data.
    - Return only the corresponding answer in the same language as the question.
    - If no match is found, respond with: "I don't have that information."

    Data: {faq_data}
    """

    response = client.chat.completions.create(
        model="meta-llama/llama-4-scout-17b-16e-instruct",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question}
        ],
        temperature=0.0,
    )

    return response.choices[0].message.content.strip()

# Main function
def main():
    faq_data = load_faq_data("cleanedTranslatedBankFAQs (1).csv")

    print("Bank FAQ Assistant is ready! Type 'exit' to quit.")
    while True:
        try:
            question = input("You: ")
            if question.lower() in ['exit', 'quit']:
                break
            answer = get_answer_from_question(question, faq_data)
            print("Assistant:", answer)
        except Exception as e:
            print("Error:", str(e))

if __name__ == "__main__":
    main()









